{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratory: transformers for sentence english to spanish translation\n",
        "\n",
        "Authors:\n",
        "Diego Villacreses"
      ],
      "metadata": {
        "id": "7bQkLtRv1riN"
      },
      "id": "7bQkLtRv1riN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load libraries"
      ],
      "metadata": {
        "id": "pv-iFLoU15Fc"
      },
      "id": "pv-iFLoU15Fc"
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "f19747c7-e8de-41d2-9b7c-e61f9cc64f6f",
      "metadata": {
        "id": "f19747c7-e8de-41d2-9b7c-e61f9cc64f6f"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "## lightning\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "##\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/home/dvillacreses/nlp')"
      ],
      "metadata": {
        "id": "K-3jT_Mc1-nS"
      },
      "id": "K-3jT_Mc1-nS",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "6Cv4T6Z_1_z_"
      },
      "id": "6Cv4T6Z_1_z_",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "MGQc4xKM17Xe"
      },
      "id": "MGQc4xKM17Xe"
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "434ffc33-1973-479c-bc9e-2638e7dfaabe",
      "metadata": {
        "id": "434ffc33-1973-479c-bc9e-2638e7dfaabe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b958f30-2ab4-426f-99a3-a6a074e48bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counted words:\n",
            "eng 13526\n",
            "spa 26437\n"
          ]
        }
      ],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 16\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "def filterPair(p):\n",
        "    try:\n",
        "        return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "            len(p[1].split(' ')) < MAX_LENGTH #and \\\n",
        "#            p[0].startswith(eng_prefixes)\n",
        "    except:\n",
        "        print(p)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def prepareData(lang1, lang2, file):\n",
        "    text = open(file, encoding='utf-8').read().split('\\n')\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in text ]\n",
        "    pairs = [pair for pair in pairs if len(pair) == 2]\n",
        "\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "\n",
        "    pairs = filterPairs(pairs)\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "file_dir = 'spa.txt'\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'spa', file_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "\n",
        "def take(n, iterable):\n",
        "    \"\"\"Return the first n items of the iterable as a list.\"\"\"\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "print(take(10, input_lang.index2word.items()))\n",
        "print(take(10, output_lang.index2word.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhI0NyDH3GQs",
        "outputId": "17ad7ef9-2e14-4630-d63c-cd88da19d6bd"
      },
      "id": "HhI0NyDH3GQs",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'SOS'), (1, 'EOS'), (2, 'go'), (3, 'hi'), (4, 'run'), (5, '!'), (6, 'who'), (7, '?'), (8, 'wow'), (9, 'duck')]\n",
            "[(0, 'SOS'), (1, 'EOS'), (2, 've'), (3, 'vete'), (4, 'vaya'), (5, 'vayase'), (6, 'hola'), (7, 'corre'), (8, '!'), (9, 'corran')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training step by step transformer"
      ],
      "metadata": {
        "id": "Yyo8_SAb8Kfe"
      },
      "id": "Yyo8_SAb8Kfe"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pl\n",
        "import math\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Define special tokens\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 16\n",
        "\n",
        "# Positional Encoding function\n",
        "def positional_encoding(max_len, hidden_dim):\n",
        "    pe = torch.zeros(max_len, hidden_dim)\n",
        "    for pos in range(max_len):\n",
        "        for i in range(0, hidden_dim, 2):\n",
        "            pe[pos, i] = math.sin(pos / (10000 ** (i / hidden_dim)))\n",
        "            pe[pos, i + 1] = math.cos(pos / (10000 ** (i / hidden_dim)))\n",
        "    return pe.unsqueeze(0)\n",
        "\n",
        "# Multihead Attention implementation\n",
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, model_dim, num_heads):\n",
        "        super(MultiheadAttention, self).__init__()\n",
        "        assert model_dim % num_heads == 0, \"model_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = model_dim // num_heads\n",
        "\n",
        "        # Linear layers to project input into Q, K, V\n",
        "        self.q_proj = nn.Linear(model_dim, model_dim)\n",
        "        self.k_proj = nn.Linear(model_dim, model_dim)\n",
        "        self.v_proj = nn.Linear(model_dim, model_dim)\n",
        "        self.out_proj = nn.Linear(model_dim, model_dim)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # Linear projections and reshape to split heads\n",
        "        q = self.q_proj(query).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.k_proj(key).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.v_proj(value).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "        attn_weights = torch.softmax(scores, dim=-1)\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # Concatenate heads and apply output projection\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.head_dim)\n",
        "        output = self.out_proj(context)\n",
        "        return output\n",
        "\n",
        "# Encoder block with multi-head attention and feedforward network\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, model_dim, num_heads, feedforward_dim, dropout=0.1):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.attention = MultiheadAttention(model_dim, num_heads)\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(model_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, model_dim),\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(model_dim)\n",
        "        self.norm2 = nn.LayerNorm(model_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Self-attention block\n",
        "        attn_out = self.attention(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_out))\n",
        "\n",
        "        # Feedforward block\n",
        "        ff_out = self.feedforward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_out))\n",
        "\n",
        "        return x\n",
        "\n",
        "# Decoder block with masked multi-head attention, encoder-decoder attention, and feedforward network\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, model_dim, num_heads, feedforward_dim, dropout=0.1):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.self_attention = MultiheadAttention(model_dim, num_heads)\n",
        "        self.enc_dec_attention = MultiheadAttention(model_dim, num_heads)\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(model_dim, feedforward_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(feedforward_dim, model_dim),\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(model_dim)\n",
        "        self.norm2 = nn.LayerNorm(model_dim)\n",
        "        self.norm3 = nn.LayerNorm(model_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        # Masked self-attention for decoder\n",
        "        self_attn_out = self.self_attention(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(self_attn_out))\n",
        "\n",
        "        # Encoder-decoder attention\n",
        "        enc_dec_attn_out = self.enc_dec_attention(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(enc_dec_attn_out))\n",
        "\n",
        "        # Feedforward block\n",
        "        ff_out = self.feedforward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_out))\n",
        "\n",
        "        return x\n",
        "\n",
        "# Transformer Encoder with multiple EncoderBlocks\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, num_layers, model_dim, num_heads, feedforward_dim, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([EncoderBlock(model_dim, num_heads, feedforward_dim, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, src, mask=None):\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, mask)\n",
        "        return src\n",
        "\n",
        "# Transformer Decoder with multiple DecoderBlocks\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, num_layers, model_dim, num_heads, feedforward_dim, dropout=0.1):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([DecoderBlock(model_dim, num_heads, feedforward_dim, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, tgt, enc_output, src_mask=None, tgt_mask=None):\n",
        "        for layer in self.layers:\n",
        "            tgt = layer(tgt, enc_output, src_mask, tgt_mask)\n",
        "        return tgt\n",
        "\n",
        "# Complete Transformer-based Translator model (encoder-decoder)\n",
        "class TransformerTranslator(pl.LightningModule):\n",
        "    def __init__(self, input_vocab_size, output_vocab_size, model_dim, num_heads, num_layers, feedforward_dim, dropout=0.1, lr=1e-4):\n",
        "        super(TransformerTranslator, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.model_dim = model_dim\n",
        "        self.lr = lr\n",
        "\n",
        "        # Embedding layers for source and target\n",
        "        self.input_embedding = nn.Embedding(input_vocab_size, model_dim)\n",
        "        self.output_embedding = nn.Embedding(output_vocab_size, model_dim)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.positional_encoding = positional_encoding(MAX_LENGTH, model_dim)\n",
        "\n",
        "        # Transformer encoder and decoder\n",
        "        self.encoder = TransformerEncoder(num_layers, model_dim, num_heads, feedforward_dim, dropout)\n",
        "        self.decoder = TransformerDecoder(num_layers, model_dim, num_heads, feedforward_dim, dropout)\n",
        "\n",
        "        # Final output layer to predict tokens\n",
        "        self.output_layer = nn.Linear(model_dim, output_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        # Get the current device (either CPU or GPU)\n",
        "        device = src.device\n",
        "\n",
        "        # Apply embedding and positional encoding, move positional encoding to the same device as src/tgt\n",
        "        src = self.input_embedding(src) + self.positional_encoding[:, :src.size(1), :].to(device)\n",
        "        tgt = self.output_embedding(tgt) + self.positional_encoding[:, :tgt.size(1), :].to(device)\n",
        "\n",
        "        # Pass through encoder and decoder\n",
        "        enc_output = self.encoder(src, src_mask)\n",
        "        dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        # Output projection\n",
        "        output = self.output_layer(dec_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "\n",
        "        # Prepare input and target for decoder\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_output = tgt[:, 1:]\n",
        "\n",
        "        # Forward pass\n",
        "        output = self(src, tgt_input)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = nn.CrossEntropyLoss()(output.reshape(-1, self.hparams.output_vocab_size), tgt_output.reshape(-1))\n",
        "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "    # Hook to print the average loss per epoch\n",
        "    def on_train_epoch_end(self):\n",
        "        avg_loss = self.trainer.callback_metrics[\"train_loss\"].item()\n",
        "        print(f\"Epoch {self.current_epoch+1} training loss: {avg_loss}\")\n",
        "\n",
        "\n",
        "# Dataset preparation\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "# Custom collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # Separate source and target sequences\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "\n",
        "    # Pad the source and target sequences\n",
        "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=0)  # padding_value=0 for padding tokens\n",
        "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "# Dummy Dataset (replace with your dataset)\n",
        "class TranslationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return tensorsFromPair(self.pairs[idx])\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_dim = 256\n",
        "nheads = 8\n",
        "num_layers = 2\n",
        "feedforward_dim = 512\n",
        "dropout = 0.2\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "n_epochs = 5\n",
        "\n",
        "# Dummy Language Class for Mapping Words to Indexes and Vice Versa\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.index2word = {}\n",
        "        self.n_words = 0  # Count of words\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "\n",
        "# Dummy data for demonstration\n",
        "input_lang = Lang()\n",
        "output_lang = Lang()\n",
        "\n",
        "for pair in pairs:\n",
        "    input_lang.add_sentence(pair[0])\n",
        "    output_lang.add_sentence(pair[1])\n",
        "\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "\n",
        "# Create dataset and dataloader\n",
        "train_dataset = TranslationDataset(pairs)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Initialize the model\n",
        "model = TransformerTranslator(input_vocab_size=input_size, output_vocab_size=output_size,\n",
        "                              model_dim=hidden_dim, num_heads=nheads, num_layers=num_layers,\n",
        "                              feedforward_dim=feedforward_dim, dropout=dropout, lr=learning_rate)\n",
        "\n",
        "# Initialize the PyTorch Lightning trainer\n",
        "trainer = pl.Trainer(max_epochs=n_epochs)\n",
        "trainer.fit(model, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520,
          "referenced_widgets": [
            "91bed4347882414cb18201b44301bfbf",
            "4a6bfd1d848a496f950c0fa4f7fbc072",
            "b48621ffd9f24cacbf1c4bb7a8b537f9",
            "315765fd0e3144f9998b2c041e4edc90",
            "fcde1de8958d411180f55c06a93e4b50",
            "a8c55243273a47ebb91ea9028d5ed931",
            "c41952c3a2504221bd9ed60a99dab406",
            "c5eef89fccf5476c90b770352874cffb",
            "0b262ab19fc84800a10fc718feb85c15",
            "6452f229baaf404c9730e92a482d9161",
            "f3ef44d0825b4ea99d56cee2acdea2ff"
          ]
        },
        "id": "BzkfRVMN8Lk9",
        "outputId": "34a984c8-7caf-47c9-9a78-eeaecfb52ad5"
      },
      "id": "BzkfRVMN8Lk9",
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name             | Type               | Params | Mode \n",
            "----------------------------------------------------------------\n",
            "0 | input_embedding  | Embedding          | 3.5 M  | train\n",
            "1 | output_embedding | Embedding          | 6.8 M  | train\n",
            "2 | encoder          | TransformerEncoder | 1.1 M  | train\n",
            "3 | decoder          | TransformerDecoder | 1.6 M  | train\n",
            "4 | output_layer     | Linear             | 6.8 M  | train\n",
            "----------------------------------------------------------------\n",
            "19.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "19.7 M    Total params\n",
            "78.636    Total estimated model params size (MB)\n",
            "71        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91bed4347882414cb18201b44301bfbf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 training loss: 0.5996176600456238\n",
            "Epoch 2 training loss: 0.08028876036405563\n",
            "Epoch 3 training loss: 0.027580171823501587\n",
            "Epoch 4 training loss: 0.01449747383594513\n",
            "Epoch 5 training loss: 0.011489653028547764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a sentence into a tensor of word indexes\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long).unsqueeze(0)  # Shape [1, seq_len]\n",
        "\n",
        "# Function to convert word indexes back to a sentence\n",
        "def sentenceFromTensor(lang, tensor):\n",
        "    return ' '.join([lang.index2word[idx.item()] for idx in tensor])\n",
        "\n",
        "# Function to translate a phrase using the trained model\n",
        "def translate_sentence(model, input_sentence, input_lang, output_lang, max_length=MAX_LENGTH):\n",
        "    # Prepare the input tensor\n",
        "    input_tensor = tensorFromSentence(input_lang, input_sentence)\n",
        "\n",
        "    # Initialize the target sentence with the SOS token\n",
        "    decoder_input = torch.tensor([[SOS_token]], dtype=torch.long)\n",
        "\n",
        "    # Move tensors to the same device as the model\n",
        "    device = model.device\n",
        "    input_tensor = input_tensor.to(device)\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Run the encoder and get the encoder output\n",
        "    with torch.no_grad():\n",
        "        encoder_output = model.input_embedding(input_tensor) + model.positional_encoding[:, :input_tensor.size(1), :].to(device)\n",
        "        encoder_output = model.encoder(encoder_output)\n",
        "\n",
        "    decoded_words = []\n",
        "\n",
        "    # Greedy decoding (one word at a time)\n",
        "    for _ in range(max_length):\n",
        "        with torch.no_grad():\n",
        "            decoder_output = model.output_embedding(decoder_input) + model.positional_encoding[:, :decoder_input.size(1), :].to(device)\n",
        "            transformer_output = model.decoder(decoder_output, encoder_output)\n",
        "            output_logits = model.output_layer(transformer_output)\n",
        "\n",
        "        # Get the most likely next word (greedy decoding)\n",
        "        next_token = output_logits[:, -1].argmax(dim=1)\n",
        "        next_word = output_lang.index2word[next_token.item()]\n",
        "\n",
        "        # Stop if EOS token is generated\n",
        "        if next_token.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "        # Append word to the decoded sentence\n",
        "        decoded_words.append(next_word)\n",
        "\n",
        "        # Update the decoder input with the new word\n",
        "        decoder_input = torch.cat((decoder_input, next_token.unsqueeze(0)), dim=1)\n",
        "\n",
        "    return ' '.join(decoded_words)\n",
        "\n",
        "# Example phrases for translation\n",
        "for phrase in ['hello', 'she is my sister', 'i am cleaning my house', 'i m scared', 'what is my name ?']:\n",
        "    input_sentence = phrase\n",
        "    output_sentence = translate_sentence(model, input_sentence, input_lang, output_lang)\n",
        "    print(f\"Translated sentence from '{input_sentence}' to: '{output_sentence}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ9icdYyVWLR",
        "outputId": "016630fc-2f94-4d6d-da29-be6475ef2b3a"
      },
      "id": "fJ9icdYyVWLR",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated sentence from 'hello' to: 've ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve'\n",
            "Translated sentence from 'she is my sister' to: 've ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve'\n",
            "Translated sentence from 'i am cleaning my house' to: 've ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve'\n",
            "Translated sentence from 'i m scared' to: 've ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve'\n",
            "Translated sentence from 'what is my name ?' to: 've ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## traning with nn.Transformer"
      ],
      "metadata": {
        "id": "0sp5EM-4Wsyx"
      },
      "id": "0sp5EM-4Wsyx"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pl\n",
        "import math\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Define special tokens\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 16\n",
        "\n",
        "# Positional Encoding function\n",
        "def positional_encoding(max_len, hidden_dim):\n",
        "    pe = torch.zeros(max_len, hidden_dim)\n",
        "    for pos in range(max_len):\n",
        "        for i in range(0, hidden_dim, 2):\n",
        "            pe[pos, i] = math.sin(pos / (10000 ** (i / hidden_dim)))\n",
        "            pe[pos, i + 1] = math.cos(pos / (10000 ** (i / hidden_dim)))\n",
        "    return pe.unsqueeze(0)\n",
        "\n",
        "# Transformer-based Translator model\n",
        "class TransformerTranslator(pl.LightningModule):\n",
        "    def __init__(self, input_vocab_size, output_vocab_size, model_dim, num_heads, num_layers, dropout=0.1, lr=1e-4):\n",
        "        super(TransformerTranslator, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.model_dim = model_dim\n",
        "        self.lr = lr\n",
        "\n",
        "        # Embedding layers for source and target\n",
        "        self.input_embedding = nn.Embedding(input_vocab_size, model_dim)\n",
        "        self.output_embedding = nn.Embedding(output_vocab_size, model_dim)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.positional_encoding = positional_encoding(MAX_LENGTH, model_dim)\n",
        "\n",
        "        # Transformer model\n",
        "        self.transformer = nn.Transformer(d_model=model_dim, nhead=num_heads, num_encoder_layers=num_layers,\n",
        "                                          num_decoder_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "        # Final output layer to predict tokens\n",
        "        self.output_layer = nn.Linear(model_dim, output_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Get the current device (either CPU or GPU)\n",
        "        device = src.device\n",
        "\n",
        "        # Apply embedding and positional encoding, move positional encoding to the same device as src/tgt\n",
        "        src = self.input_embedding(src) + self.positional_encoding[:, :src.size(1), :].to(device)\n",
        "        tgt = self.output_embedding(tgt) + self.positional_encoding[:, :tgt.size(1), :].to(device)\n",
        "\n",
        "        # Pass through transformer and output layer\n",
        "        output = self.transformer(src, tgt)\n",
        "        output = self.output_layer(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "\n",
        "        # Prepare input and target for decoder\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_output = tgt[:, 1:]\n",
        "\n",
        "        # Forward pass\n",
        "        output = self(src, tgt_input)\n",
        "\n",
        "        # Compute loss using reshape instead of view\n",
        "        loss = nn.CrossEntropyLoss()(output.reshape(-1, self.hparams.output_vocab_size), tgt_output.reshape(-1))\n",
        "\n",
        "        # Log batch loss\n",
        "        self.log('train_loss', loss, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "    # Hook to print the average loss per epoch\n",
        "    def on_train_epoch_end(self):\n",
        "        avg_loss = self.trainer.callback_metrics[\"train_loss\"].item()\n",
        "        print(f\"Epoch {self.current_epoch+1} training loss: {avg_loss}\")\n",
        "\n",
        "# Dummy Language Class for Mapping Words to Indexes and Vice Versa\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.index2word = {}\n",
        "        self.n_words = 0  # Count of words\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "\n",
        "# Create input and output language objects\n",
        "input_lang = Lang()\n",
        "output_lang = Lang()\n",
        "\n",
        "\n",
        "# Populate the language objects with the example data\n",
        "for pair in pairs:\n",
        "    input_lang.add_sentence(pair[0])\n",
        "    output_lang.add_sentence(pair[1])\n",
        "\n",
        "# Dataset preparation\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long)  # No need to add batch dimension here\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "# Custom Dataset for translation\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, pairs):\n",
        "        self.pairs = pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return tensorsFromPair(self.pairs[idx])\n",
        "\n",
        "# Custom collate function for padding\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "\n",
        "    # Pad sequences to ensure uniform length\n",
        "    src_batch = pad_sequence(src_batch, batch_first=True, padding_value=0)  # Padding token = 0\n",
        "    tgt_batch = pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_dim = 256\n",
        "nheads = 8\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "n_epochs = 5\n",
        "\n",
        "\n",
        "input_size = input_lang.n_words\n",
        "output_size = output_lang.n_words\n",
        "\n",
        "# Create dataset and dataloader\n",
        "train_dataset = TranslationDataset(pairs)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Initialize the model\n",
        "model = TransformerTranslator(input_vocab_size=input_size, output_vocab_size=output_size,\n",
        "                              model_dim=hidden_dim, num_heads=nheads, num_layers=num_layers, dropout=dropout, lr=learning_rate)\n",
        "\n",
        "# Initialize the PyTorch Lightning trainer\n",
        "trainer = pl.Trainer(max_epochs=n_epochs)  # Set gpus=0 to use CPU, adjust if GPU is available\n",
        "trainer.fit(model, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "b585b2021fdc4d91806b5d467b61ae30",
            "4332b09c7dfb4e3fb6e30ae36961fa6a",
            "6a5834025d3b4020b27ab1e517c0698d",
            "1ed8057947bb402bab20f54c0e48486d",
            "d55761f9953c48e78cd63bcf62b2ce5c",
            "116f6eb8de3e49c3b2daa5ebfca749d1",
            "949a97ab45d2489d95da5fb317da50c6",
            "9fc79bfe0cfa4815bf048e425683ad51",
            "0c278ca23d194d44b8ee66a030a6ab0a",
            "9b7b7efcd4cb4509bbe7880b15d0d889",
            "a2de03d605e046728acd1f7819716481"
          ]
        },
        "id": "y92nqufqWwLP",
        "outputId": "d58fd9d3-7927-4222-b16f-b7bcb0b8c9b0"
      },
      "id": "y92nqufqWwLP",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name             | Type        | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | input_embedding  | Embedding   | 3.5 M  | train\n",
            "1 | output_embedding | Embedding   | 6.8 M  | train\n",
            "2 | transformer      | Transformer | 5.8 M  | train\n",
            "3 | output_layer     | Linear      | 6.8 M  | train\n",
            "---------------------------------------------------------\n",
            "22.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "22.8 M    Total params\n",
            "91.248    Total estimated model params size (MB)\n",
            "58        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b585b2021fdc4d91806b5d467b61ae30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 training loss: 0.7338055968284607\n",
            "Epoch 2 training loss: 0.117411307990551\n",
            "Epoch 3 training loss: 0.04921085014939308\n",
            "Epoch 4 training loss: 0.027806900441646576\n",
            "Epoch 5 training loss: 0.02332763560116291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a sentence into a tensor of word indexes\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long).unsqueeze(0)  # Shape [1, seq_len]\n",
        "\n",
        "# Function to convert word indexes back to a sentence\n",
        "def sentenceFromTensor(lang, tensor):\n",
        "    return ' '.join([lang.index2word[idx.item()] for idx in tensor])\n",
        "\n",
        "# Function to translate a phrase using the trained model\n",
        "def translate_sentence(model, input_sentence, input_lang, output_lang, max_length=MAX_LENGTH):\n",
        "    # Prepare the input tensor\n",
        "    input_tensor = tensorFromSentence(input_lang, input_sentence)\n",
        "\n",
        "    # Initialize the target sentence with the SOS token\n",
        "    decoder_input = torch.tensor([[SOS_token]], dtype=torch.long)\n",
        "\n",
        "    # Move tensors to the same device as the model\n",
        "    input_tensor = input_tensor.to(model.device)\n",
        "    decoder_input = decoder_input.to(model.device)\n",
        "\n",
        "    # Run the encoder and get the encoder output\n",
        "    with torch.no_grad():\n",
        "        encoder_output = model.input_embedding(input_tensor) + model.positional_encoding[:, :input_tensor.size(1), :]\n",
        "        encoder_output = model.transformer.encoder(encoder_output)\n",
        "\n",
        "    decoded_words = []\n",
        "\n",
        "    # Greedy decoding (one word at a time)\n",
        "    for _ in range(max_length):\n",
        "        with torch.no_grad():\n",
        "            decoder_output = model.output_embedding(decoder_input) + model.positional_encoding[:, :decoder_input.size(1), :]\n",
        "            transformer_output = model.transformer.decoder(\n",
        "                decoder_output, encoder_output\n",
        "            )\n",
        "            output_logits = model.output_layer(transformer_output)\n",
        "\n",
        "        # Get the most likely next word (greedy decoding)\n",
        "        next_token = output_logits[:, -1].argmax(dim=1)\n",
        "        next_word = output_lang.index2word[next_token.item()]\n",
        "\n",
        "        # Stop if EOS token is generated\n",
        "        if next_token.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "        # Append word to the decoded sentence\n",
        "        decoded_words.append(next_word)\n",
        "\n",
        "        # Update the decoder input with the new word\n",
        "        decoder_input = torch.cat((decoder_input, next_token.unsqueeze(0)), dim=1)\n",
        "\n",
        "    return ' '.join(decoded_words)\n",
        "\n",
        "\n",
        "for phrase in ['hello','she is my sister','i am cleaning my house','i m scared','what is my name ?']:\n",
        "    input_sentence = phrase\n",
        "    output_sentence = translate_sentence(model, input_sentence, input_lang, output_lang)\n",
        "    print(f\"Translated sentence from {input_sentence} to: {output_sentence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lxtVBSocJKZ",
        "outputId": "ba4e0ad9-1443-4ea2-b2d7-a03127507fb4"
      },
      "id": "5lxtVBSocJKZ",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated sentence from hello to: ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve\n",
            "Translated sentence from she is my sister to: ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve\n",
            "Translated sentence from i am cleaning my house to: ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve\n",
            "Translated sentence from i m scared to: repruebas repruebas repruebas repruebas repruebas repruebas repruebas repruebas repruebas repruebas repruebas\n",
            "Translated sentence from what is my name ? to: ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve ve\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91bed4347882414cb18201b44301bfbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a6bfd1d848a496f950c0fa4f7fbc072",
              "IPY_MODEL_b48621ffd9f24cacbf1c4bb7a8b537f9",
              "IPY_MODEL_315765fd0e3144f9998b2c041e4edc90"
            ],
            "layout": "IPY_MODEL_fcde1de8958d411180f55c06a93e4b50"
          }
        },
        "4a6bfd1d848a496f950c0fa4f7fbc072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8c55243273a47ebb91ea9028d5ed931",
            "placeholder": "​",
            "style": "IPY_MODEL_c41952c3a2504221bd9ed60a99dab406",
            "value": "Epoch 4: 100%"
          }
        },
        "b48621ffd9f24cacbf1c4bb7a8b537f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5eef89fccf5476c90b770352874cffb",
            "max": 2189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b262ab19fc84800a10fc718feb85c15",
            "value": 2189
          }
        },
        "315765fd0e3144f9998b2c041e4edc90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6452f229baaf404c9730e92a482d9161",
            "placeholder": "​",
            "style": "IPY_MODEL_f3ef44d0825b4ea99d56cee2acdea2ff",
            "value": " 2189/2189 [00:46&lt;00:00, 46.91it/s, v_num=62, train_loss_step=0.0103, train_loss_epoch=0.0115]"
          }
        },
        "fcde1de8958d411180f55c06a93e4b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a8c55243273a47ebb91ea9028d5ed931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c41952c3a2504221bd9ed60a99dab406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5eef89fccf5476c90b770352874cffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b262ab19fc84800a10fc718feb85c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6452f229baaf404c9730e92a482d9161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ef44d0825b4ea99d56cee2acdea2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b585b2021fdc4d91806b5d467b61ae30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4332b09c7dfb4e3fb6e30ae36961fa6a",
              "IPY_MODEL_6a5834025d3b4020b27ab1e517c0698d",
              "IPY_MODEL_1ed8057947bb402bab20f54c0e48486d"
            ],
            "layout": "IPY_MODEL_d55761f9953c48e78cd63bcf62b2ce5c"
          }
        },
        "4332b09c7dfb4e3fb6e30ae36961fa6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_116f6eb8de3e49c3b2daa5ebfca749d1",
            "placeholder": "​",
            "style": "IPY_MODEL_949a97ab45d2489d95da5fb317da50c6",
            "value": "Epoch 4: 100%"
          }
        },
        "6a5834025d3b4020b27ab1e517c0698d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fc79bfe0cfa4815bf048e425683ad51",
            "max": 2189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c278ca23d194d44b8ee66a030a6ab0a",
            "value": 2189
          }
        },
        "1ed8057947bb402bab20f54c0e48486d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b7b7efcd4cb4509bbe7880b15d0d889",
            "placeholder": "​",
            "style": "IPY_MODEL_a2de03d605e046728acd1f7819716481",
            "value": " 2189/2189 [00:52&lt;00:00, 41.89it/s, v_num=58, train_loss_step=0.0261, train_loss_epoch=0.0233]"
          }
        },
        "d55761f9953c48e78cd63bcf62b2ce5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "116f6eb8de3e49c3b2daa5ebfca749d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "949a97ab45d2489d95da5fb317da50c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fc79bfe0cfa4815bf048e425683ad51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c278ca23d194d44b8ee66a030a6ab0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b7b7efcd4cb4509bbe7880b15d0d889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2de03d605e046728acd1f7819716481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}